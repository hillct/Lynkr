
# Primary model provider
# Options: ollama, openrouter, azure-openai,openai, azure-anthropic, databricks
MODEL_PROVIDER=azure-openai

# Ollama endpoint (local by default)
OLLAMA_ENDPOINT=http://localhost:11434

# Ollama model to use (must support tool calling for best results)
# Recommended: llama3.1:8b, llama3.2, qwen3, mistral:7b-instruct
# NOT recommended for tools: qwen2.5-coder (code-only, slow with tools)
OLLAMA_MODEL=llama3.1:8b

# Disable fallback to cloud providers (Ollama-only mode)
FALLBACK_ENABLED=false

# Note: PREFER_OLLAMA is ignored when MODEL_PROVIDER=ollama
# Max tools before performance degradation (auto-limited to 8 essential tools)
OLLAMA_MAX_TOOLS_FOR_ROUTING=2

# ==============================================================================
# OpenRouter Configuration (Multi-Model Provider)
# ==============================================================================

# OpenRouter API key (get from https://openrouter.ai/keys)
OPENROUTER_API_KEY=<your-openrouter-api-key>


# OpenRouter model to use
# Options: openai/gpt-4o, anthropic/claude-3.5-sonnet, google/gemini-pro-1.5, openai/gpt-oss-120b, etc.
# gpt-4o-mini is recommended for affordable tool calling ($0.15/$0.60 per 1M tokens)
OPENROUTER_MODEL=amazon/nova-2-lite-v1:free

# OpenRouter endpoint
OPENROUTER_ENDPOINT=https://openrouter.ai/api/v1/chat/completions

# Max tools before routing to heavier provider (OpenRouter handles more than Ollama)
OPENROUTER_MAX_TOOLS_FOR_ROUTING=15

# ==============================================================================
# Cloud Provider Credentials (NOT NEEDED for Ollama-only mode)
# ==============================================================================
# These are commented out since we're running in Ollama-only mode.
# Uncomment and configure if you want to enable fallback.

# Databricks (optional fallback)
#DATABRICKS_API_BASE=https://a1db-7405615420308831.11.azuredatabricks.net
#DATABRICKS_API_KEY=dapi51a744e900a5b5cd993206929ff222b73

# Azure Anthropic (optional fallback)
# AZURE_ANTHROPIC_ENDPOINT=https://your-endpoint.openai.azure.com
# AZURE_ANTHROPIC_API_KEY=your-azure-key

# Azure OpenAI (optional fallback)
# Azure OpenAI resource endpoint (from Azure Portal)
# Format: https://<your-resource-name>.openai.azure.com
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com
# Azure OpenAI API key (found in Azure Portal under Keys and Endpoint)
AZURE_OPENAI_API_KEY=XXX-YYYYY

# Deployment name (the model deployment you created in Azure)
# This can point to any Azure model: gpt-4o, gpt-5, gpt-5-codex, etc.
AZURE_OPENAI_DEPLOYMENT=Kimi-K2-Thinking

# ==============================================================================
# OpenAI Configuration (Direct OpenAI API)
# ==============================================================================

# OpenAI API key (from https://platform.openai.com/api-keys)
# OPENAI_API_KEY=sk-your-openai-api-key

# OpenAI model to use
# Options: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo, o1-preview, o1-mini
# Default: gpt-4o
# OPENAI_MODEL=gpt-4o

# OpenAI API endpoint (usually don't need to change this)
# Default: https://api.openai.com/v1/chat/completions
# OPENAI_ENDPOINT=https://api.openai.com/v1/chat/completions

# OpenAI organization ID (optional, for organization-level API keys)
# OPENAI_ORGANIZATION=org-your-org-id
# ==============================================================================
# Server Configuration
# ==============================================================================

PORT=8080
LOG_LEVEL=debug  # Use 'debug' for detailed logs, 'info' for production
WEB_SEARCH_ENDPOINT=http://localhost:8888/search

# Tool execution mode: where to execute tools (Write, Read, Bash, etc.)
# - server: Execute tools on the server (default)
# - passthrough/client: Return tool calls to CLI for local execution
TOOL_EXECUTION_MODE=client

# ==============================================================================
# Performance Tuning (Optional)
# ==============================================================================

# Load shedding thresholds
LOAD_SHEDDING_HEAP_THRESHOLD=0.95
# LOAD_SHEDDING_EVENT_LOOP_DELAY=100
